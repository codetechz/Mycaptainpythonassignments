# -*- coding: utf-8 -*-
"""LogisticRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sbijdlap44rq6vDWWyeyVhJf0W9BBN3U
"""

import pandas as pd

col_names=['Pregnancies','Glucose','BP','SkinThickness','Insulin','BMI','DPF','Age','Outcome']
pima=pd.read_csv("diabetes.csv",header=0,names=col_names)

pima.head()

feature_cols=['Pregnancies','Glucose','BP','Insulin','BMI','DPF','Age']

X=pima[feature_cols]
Y=pima.Outcome

X.head()

Y

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.30,random_state=20)
#random_state ensures that same randomization is used each time when you run the code,resulting in the same splits of the data

X_train.head()

from sklearn.linear_model import LogisticRegression

logreg=LogisticRegression()
logreg.fit(X_train,Y_train)

Y_pred=logreg.predict(X_test)

from sklearn import metrics
cnf=metrics.confusion_matrix(Y_test,Y_pred)

cnf   #[[True_Positive , False_Positive],
      # [False_Negative , True_Negative]]

#returns the fraction of correctly classified samples
metrics.accuracy_score(Y_test,Y_pred,normalize=True)

#returns the number of correctly classified samples
metrics.accuracy_score(Y_test,Y_pred,normalize=False)